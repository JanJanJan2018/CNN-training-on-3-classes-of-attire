{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install augmentor\n",
    "# pip install augmentor --upgrade\n",
    "\n",
    "# then in python run image resize and shape commands:\n",
    "\n",
    "# This script should be ran in your 'rawData' folder where your 'photos' folder is with each class of photos\n",
    "# in their respective folder, ie. rawData --> photos --> workShirt\n",
    "#                                                    --> dressy\n",
    "#                                                    --> suit\n",
    "# this script with the Augmentor package creates a folder named 'output' that has the same directory of photos and subfolders\n",
    "# that it places the augmented images in, this will take some time to do all the transformations to the images\n",
    "# the documentation was pulled from: https://github.com/mdbloice/Augmentor\n",
    "\n",
    "#import Augmentor\n",
    "#p = Augmentor.Pipeline(\"/path/to/images\")\n",
    "\n",
    "#p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "#p.zoom(probability=0.5, min_factor=1.1, max_factor=1.5)\n",
    "\n",
    "#p.sample(10000)\n",
    "\n",
    "#other ways to use the pipeline of Augmentor\n",
    "#p.sample(100, multi_threaded=False) #if images are very small, the processing can take a while, use this if so\n",
    "\n",
    "#p.rotate90(probability=0.5)\n",
    "#p.rotate270(probability=0.5)\n",
    "#p.flip_left_right(probability=0.8)\n",
    "#p.flip_top_bottom(probability=0.3)\n",
    "#p.crop_random(probability=1, percentage_area=0.5)\n",
    "#p.resize(probability=1.0, width=120, height=120)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code was already ran, but here for you if you want to create your own resized and augmented images, don't run this code otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is from: https://github.com/JanJanJan2018/BvS/blob/master/augment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## augment.py\n",
    "\n",
    "import sys\n",
    "import Augmentor\n",
    "\n",
    "folder_name='folder'\n",
    "p= Augmentor.Pipeline(source_directory=folder_name,save_format=\"png\")\n",
    "p.flip_left_right(0.5)\n",
    "p.black_and_white(0.1)\n",
    "p.gaussian_distortion(probability=0.4, grid_width=7, grid_height=6\n",
    "                      , magnitude=6, corner=\"ul\", method=\"in\", mex=0.5, mey=0.5, sdx=0.05, sdy=0.05)\n",
    "\n",
    "p.rotate(0.3, 10,10)\n",
    "p.skew(0.4,0.5)\n",
    "p.skew_tilt(0.6,0.8)\n",
    "p.skew_left_right(0.5, magnitude=0.8)\n",
    "p.sample(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code I used to augment my photo images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 390 image(s) found.\n",
      "Output directory set to ./rawData/proPhotos\\output."
     ]
    }
   ],
   "source": [
    "import Augmentor\n",
    "\n",
    "p = Augmentor.Pipeline(\"./rawData/proPhotos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.rotate90(probability=0.5)\n",
    "p.rotate270(probability=0.5)\n",
    "p.flip_left_right(probability=0.8)\n",
    "#p.flip_top_bottom(probability=0.3)\n",
    "p.crop_random(probability=1, percentage_area=0.95)\n",
    "p.resize(probability=1.0, width=224, height=224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 241_Janis Corona©KaoriSuzuki.jpg: 100%|█████████████████████████| 5000/5000 [1:59:42<00:00,  1.44s/ Samples]\n"
     ]
    }
   ],
   "source": [
    "p.sample(5000, multi_threaded = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now you can start running the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file produced resized 224 X 224 pixel images of suit, dressy, and workShirt classes \n",
    "but the program uses only binary classes, so I moved the dressy and workShirt classes into a folder called NotSuit, \n",
    "so that the CNN would classify probability using tensorflow of being a suit image or an image of attire that is not a suit.\n",
    "There are 2800 resized images of NotSuit and 2200 images of suit, for a total of 5,000 images to split into training and\n",
    "testing sets. The folder is located at C:/Users/m/Desktop/ML in R and Python/PhotosAnalysis/Augmented 224 Suit NotSuit/NotSuit \n",
    "and at C:/Users/m/Desktop/ML in R and Python/PhotosAnalysis/Augmented 224 Suit NotSuit/suit     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is from https://github.com/JanJanJan2018/BvS/blob/master/build_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build_model.py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#model's unit definitions\n",
    "class model_tools:\n",
    "    # Defined functions for all the basic tensorflow components that we needed for building a model.\n",
    "    # function definitions are in the respective comments\n",
    "\n",
    "    def add_weights(self,shape):\n",
    "        # a common method to create all sorts of weight connections\n",
    "        # takes in shapes of previous and new layer as a list e.g. [2,10]\n",
    "        # starts with random values of that shape.\n",
    "        return tf.Variable(tf.truncated_normal(shape=shape, stddev=0.05))\n",
    "\n",
    "    def add_biases(self,shape):\n",
    "        # a common method to add create biases with default=0.05\n",
    "        # takes in shape of the current layer e.g. x=10\n",
    "        return tf.Variable(tf.constant(0.05, shape=shape))\n",
    "\n",
    "    def conv_layer(self,layer, kernel, input_shape, output_shape, stride_size):\n",
    "        #convolution occurs here.\n",
    "        #create weights and biases for the given layer shape\n",
    "        weights = self.add_weights([kernel, kernel, input_shape, output_shape])\n",
    "        biases = self.add_biases([output_shape])\n",
    "        #stride=[image_jump,row_jump,column_jump,color_jump]=[1,1,1,1] mostly\n",
    "        stride = [1, stride_size, stride_size, 1]\n",
    "        #does a convolution scan on the given image\n",
    "        layer = tf.nn.conv2d(layer, weights, strides=stride, padding='SAME') + biases\n",
    "        return layer\n",
    "\n",
    "    def pooling_layer(self,layer, kernel_size, stride_size):\n",
    "        # basically it reduces the complexity involved by only taking the important features alone\n",
    "        # many types of pooling is there.. average pooling, max pooling..\n",
    "        # max pooling takes the maximum of the given kernel\n",
    "        #kernel=[image_jump,rows,columns,depth]\n",
    "        kernel = [1, kernel_size, kernel_size, 1]\n",
    "        #stride=[image_jump,row_jump,column_jump,color_jump]=[1,2,2,1] mostly\n",
    "        stride = [1, stride_size, stride_size, 1]\n",
    "        return tf.nn.max_pool(layer, ksize=kernel, strides=stride, padding='SAME')\n",
    "\n",
    "    def flattening_layer(self,layer):\n",
    "        #make it single dimensional\n",
    "        input_size = layer.get_shape().as_list()\n",
    "        new_size = input_size[-1] * input_size[-2] * input_size[-3]\n",
    "        return tf.reshape(layer, [-1, new_size]),new_size\n",
    "\n",
    "    def fully_connected_layer(self,layer, input_shape, output_shape):\n",
    "        #create weights and biases for the given layer shape\n",
    "        weights = self.add_weights([input_shape, output_shape])\n",
    "        biases = self.add_biases([output_shape])\n",
    "        #most important operation\n",
    "        layer = tf.matmul(layer,weights) + biases  # mX+b\n",
    "        return layer\n",
    "\n",
    "    def activation_layer(self,layer):\n",
    "        # we use Rectified linear unit Relu. it's the standard activation layer used.\n",
    "        # there are also other layer like sigmoid,tanh..etc. but relu is more efficent.\n",
    "        # function: 0 if x<0 else x.\n",
    "        return tf.nn.relu(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is from https://github.com/JanJanJan2018/BvS/blob/master/model_architecture.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model_architecture.py\n",
    "\n",
    "from build_model import model_tools\n",
    "import tensorflow as tf\n",
    "model=model_tools()\n",
    "\n",
    "def generate_model(images_ph,number_of_classes):\n",
    "    #MODEL ARCHITECTURE:\n",
    "    #level 1 convolution\n",
    "    network=model.conv_layer(images_ph,5,3,16,1)\n",
    "    network=model.pooling_layer(network,5,2)\n",
    "    network=model.activation_layer(network)\n",
    "    print(network)\n",
    "\n",
    "    #level 2 convolution\n",
    "    network=model.conv_layer(network,4,16,32,1)\n",
    "    network=model.pooling_layer(network,4,2)\n",
    "    network=model.activation_layer(network)\n",
    "    print(network)\n",
    "\n",
    "    #level 3 convolution\n",
    "    network=model.conv_layer(network,3,32,64,1)\n",
    "    network=model.pooling_layer(network,3,2)\n",
    "    network=model.activation_layer(network)\n",
    "    print(network)\n",
    "\n",
    "    #flattening layer\n",
    "    network,features=model.flattening_layer(network)\n",
    "    print(network)\n",
    "\n",
    "    #fully connected layer\n",
    "    network=model.fully_connected_layer(network,features,1024)\n",
    "    network=model.activation_layer(network)\n",
    "    print(network)\n",
    "\n",
    "    #output layer\n",
    "    network=model.fully_connected_layer(network,1024,number_of_classes)\n",
    "    print(network)\n",
    "    return network\n",
    "\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    images_ph = tf.placeholder(tf.float32, shape=[None, 100,100,3])\n",
    "    generate_model(images_ph,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is from: https://github.com/JanJanJan2018/BvS/blob/master/predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict.py\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from build_model import model_tools\n",
    "\n",
    "model=model_tools()\n",
    "model_folder='checkpoints'\n",
    "image='sup.jpg'\n",
    "img=cv2.imread(image)\n",
    "session=tf.Session()\n",
    "img=cv2.resize(img,(100,100))\n",
    "img=img.reshape(1,100,100,3)\n",
    "labels = np.zeros((1, 2))\n",
    "\n",
    "#Create a saver object to load the model\n",
    "saver = tf.train.import_meta_graph(os.path.join(model_folder,'.meta'))\n",
    "\n",
    "#restore the model from our checkpoints folder\n",
    "saver.restore(session,os.path.join(model_folder,'.\\\\'))\n",
    "\n",
    "#Create graph object for getting the same network architecture\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "#Get the last layer of the network by it's name which includes all the previous layers too\n",
    "network = graph.get_tensor_by_name(\"add_4:0\")\n",
    "\n",
    "#create placeholders to pass the image and get output labels\n",
    "im_ph= graph.get_tensor_by_name(\"Placeholder:0\")\n",
    "label_ph = graph.get_tensor_by_name(\"Placeholder_1:0\")\n",
    "\n",
    "#Inorder to make the output to be either 0 or 1.\n",
    "network=tf.nn.sigmoid(network)\n",
    "\n",
    "# Creating the feed_dict that is required to be fed to calculate y_pred\n",
    "feed_dict_testing = {im_ph: img, label_ph: labels}\n",
    "result=session.run(network, feed_dict=feed_dict_testing)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is from: https://github.com/JanJanJan2018/BvS/blob/master/preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing.py\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def image_processing(raw_data,data_path,height,width):\n",
    "    class_labels=[]\n",
    "    category_count=0\n",
    "    for i in os.walk(raw_data):\n",
    "        if len(i[2])>0:\n",
    "            counter=0\n",
    "            images=i[2]\n",
    "            class_name=i[0].strip('\\\\')\n",
    "            print(class_name)\n",
    "            path=os.path.join(data_path,class_labels[category_count])\n",
    "            for image in images:\n",
    "                im=cv2.imread(class_name+'\\\\'+image)\n",
    "                im=cv2.resize(im,(height,width))\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                cv2.imwrite(os.path.join(path,str(counter)+'.jpg'),im)\n",
    "                counter+=1\n",
    "            category_count+=1\n",
    "        else:\n",
    "            number_of_classes=len(i[1])\n",
    "            print(number_of_classes,i[1])\n",
    "            class_labels=i[1][:]\n",
    "\n",
    "if __name__=='__main__':\n",
    "    height = 100\n",
    "    width = 100\n",
    "    raw_data = 'rawdata'\n",
    "    data_path = 'data'\n",
    "    if not os.path.exists(data_path):\n",
    "        image_processing(raw_data, data_path, height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is from: https://github.com/JanJanJan2018/BvS/blob/master/config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## config.py\n",
    "\n",
    "import preprocessing as ppr\n",
    "import os\n",
    "\n",
    "#Parameters\n",
    "raw_data='rawdata'\n",
    "data_path='data'\n",
    "height=100\n",
    "width=100\n",
    "if not os.path.exists(data_path):\n",
    "    ppr.image_processing(raw_data,data_path,height,width)\n",
    "all_classes = os.listdir(data_path)\n",
    "number_of_classes = len(all_classes)\n",
    "color_channels=3\n",
    "epochs=300\n",
    "batch_size=10\n",
    "batch_counter=0\n",
    "model_save_name='checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is from: https://github.com/JanJanJan2018/BvS/blob/master/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## utils.py\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from config import *\n",
    "import random\n",
    "\n",
    "#tools for image processing and data handing.\n",
    "class utils:\n",
    "    image_count = []\n",
    "    count_buffer=[]\n",
    "    class_buffer=all_classes[:]\n",
    "    def __init__(self):\n",
    "        self.image_count = []\n",
    "        self.count_buffer = []\n",
    "        for i in os.walk(data_path):\n",
    "            if len(i[2]):\n",
    "                self.image_count.append(len(i[2]))\n",
    "        self.count_buffer=self.image_count[:]\n",
    "\n",
    "    # processing images into arrays and dispatch as batches whenever called.\n",
    "    def batch_dispatch(self,batch_size=batch_size):\n",
    "        global batch_counter\n",
    "        if sum(self.count_buffer):\n",
    "\n",
    "            class_name = random.choice(self.class_buffer)\n",
    "            choice_index = all_classes.index(class_name)\n",
    "            choice_count = self.count_buffer[choice_index]\n",
    "            if choice_count==0:\n",
    "                class_name=all_classes[self.count_buffer.index(max(self.count_buffer))]\n",
    "                choice_index = all_classes.index(class_name)\n",
    "                choice_count = self.count_buffer[choice_index]\n",
    "\n",
    "            slicer=batch_size if batch_size<choice_count else choice_count\n",
    "            img_ind=self.image_count[choice_index]-choice_count\n",
    "            indices=[img_ind,img_ind+slicer]\n",
    "            images = self.generate_images(class_name,indices)\n",
    "            labels = self.generate_labels(class_name,slicer)\n",
    "\n",
    "            self.count_buffer[choice_index]=self.count_buffer[choice_index]-slicer\n",
    "        else:\n",
    "            images,labels=(None,)*2\n",
    "        return images, labels\n",
    "\n",
    "    #gives one hot for the respective labels\n",
    "    def generate_labels(self,class_name,number_of_samples):\n",
    "        one_hot_labels=[0]*number_of_classes\n",
    "        one_hot_labels[all_classes.index(class_name)]=1\n",
    "        one_hot_labels=[one_hot_labels]*number_of_samples\n",
    "        #one_hot_labels=tf.one_hot(indices=[all_classes.index(class_name)]*number_of_samples,depth=number_of_classes)\n",
    "        return one_hot_labels\n",
    "\n",
    "    # image operations\n",
    "    def generate_images(self,class_name,indices):\n",
    "        batch_images=[]\n",
    "        choice_folder=os.path.join(data_path,class_name)\n",
    "        selected_images=os.listdir(choice_folder)[indices[0]:indices[1]]\n",
    "        for image in selected_images:\n",
    "            img=cv2.imread(os.path.join(choice_folder,image))\n",
    "            batch_images.append(img)\n",
    "        return batch_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is from: https://github.com/JanJanJan2018/BvS/blob/master/trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trainer.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from utils import utils\n",
    "from build_model import model_tools\n",
    "import model_architecture\n",
    "from tensorflow.python.client import device_lib\n",
    "from config import *\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "session=tf.Session()\n",
    "#create Placeholders for images and labels\n",
    "images_ph=tf.placeholder(tf.float32,shape=[None,height,width,color_channels])\n",
    "labels_ph=tf.placeholder(tf.float32,shape=[None,number_of_classes])\n",
    "\n",
    "#training happens here\n",
    "def trainer(network,number_of_images):\n",
    "    #find error like squared error but better\n",
    "    cross_entropy=tf.nn.softmax_cross_entropy_with_logits_v2(logits=network,labels=labels_ph)\n",
    "\n",
    "    #now minize the above error\n",
    "    #calculate the total mean of all the errors from all the nodes\n",
    "    cost=tf.reduce_mean(cross_entropy)\n",
    "    tf.summary.scalar(\"cost\", cost)#for tensorboard visualisation\n",
    "\n",
    "    #Now backpropagate to minimise the cost in the network.\n",
    "    optimizer=tf.train.AdamOptimizer().minimize(cost)\n",
    "    #print(optimizer)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(model_save_name, graph=tf.get_default_graph())\n",
    "    merged = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver(max_to_keep=4)\n",
    "    counter=0\n",
    "    for epoch in range(epochs):\n",
    "        tools = utils()\n",
    "        for batch in range(int(number_of_images / batch_size)):\n",
    "            counter+=1\n",
    "            images, labels = tools.batch_dispatch()\n",
    "            if images == None:\n",
    "                break\n",
    "            loss,summary = session.run([cost,merged], feed_dict={images_ph: images, labels_ph: labels})\n",
    "            print('loss', loss)\n",
    "            session.run(optimizer, feed_dict={images_ph: images, labels_ph: labels})\n",
    "\n",
    "            print('Epoch number ', epoch, 'batch', batch, 'complete')\n",
    "            writer.add_summary(summary,counter)\n",
    "        saver.save(session, os.path.join(model_save_name))\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    tools=utils()\n",
    "    model=model_tools()\n",
    "    network=model_architecture.generate_model(images_ph,number_of_classes)\n",
    "    print (network)\n",
    "    number_of_images = sum([len(files) for r, d, files in os.walk(\"data\")])\n",
    "    trainer(network,number_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The following is all the code in one file from: https://github.com/JanJanJan2018/BvS/blob/master/trainer_in_single_file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trainer_in_single_file.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import preprocessing as ppr\n",
    "from utils import utils\n",
    "from build_model import model_tools\n",
    "import model_architecture as ma\n",
    "from tensorflow.python.client import device_lib\n",
    "from config import *\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "\n",
    "#Parameters\n",
    "raw_data='rawdata'\n",
    "data_path='data'\n",
    "height=100\n",
    "width=100\n",
    "if not os.path.exists(data_path):\n",
    "    ppr.image_processing(raw_data,data_path,height,width)\n",
    "all_classes = os.listdir(data_path)\n",
    "number_of_classes = len(all_classes)\n",
    "color_channels=3\n",
    "epochs=300\n",
    "batch_size=10\n",
    "batch_counter=0\n",
    "model_save_name='checkpoints\\\\'\n",
    "\n",
    "\n",
    "session=tf.Session()\n",
    "\n",
    "#create Placeholders for images and labels\n",
    "images_ph=tf.placeholder(tf.float32,shape=[None,height,width,color_channels])\n",
    "labels_ph=tf.placeholder(tf.float32,shape=[None,number_of_classes])\n",
    "\n",
    "#model's unit definitions\n",
    "class model_tools:\n",
    "    # Defined functions for all the basic tensorflow components that we needed for building a model.\n",
    "    # function definitions are in the respective comments\n",
    "\n",
    "    def add_weights(self,shape):\n",
    "        # a common method to create all sorts of weight connections\n",
    "        # takes in shapes of previous and new layer as a list e.g. [2,10]\n",
    "        # starts with random values of that shape.\n",
    "        return tf.Variable(tf.truncated_normal(shape=shape, stddev=0.05))\n",
    "\n",
    "    def add_biases(self,shape):\n",
    "        # a common method to add create biases with default=0.05\n",
    "        # takes in shape of the current layer e.g. x=10\n",
    "        return tf.Variable(tf.constant(0.05, shape=shape))\n",
    "\n",
    "    def conv_layer(self,layer, kernel, input_shape, output_shape, stride_size):\n",
    "        #convolution occurs here.\n",
    "        #create weights and biases for the given layer shape\n",
    "        weights = self.add_weights([kernel, kernel, input_shape, output_shape])\n",
    "        biases = self.add_biases([output_shape])\n",
    "        #stride=[image_jump,row_jump,column_jump,color_jump]=[1,1,1,1] mostly\n",
    "        stride = [1, stride_size, stride_size, 1]\n",
    "        #does a convolution scan on the given image\n",
    "        layer = tf.nn.conv2d(layer, weights, strides=stride, padding='SAME') + biases\n",
    "        return layer\n",
    "\n",
    "    def pooling_layer(self,layer, kernel_size, stride_size):\n",
    "        # basically it reduces the complexity involved by only taking the important features alone\n",
    "        # many types of pooling is there.. average pooling, max pooling..\n",
    "        # max pooling takes the maximum of the given kernel\n",
    "        #kernel=[image_jump,rows,columns,depth]\n",
    "        kernel = [1, kernel_size, kernel_size, 1]\n",
    "        #stride=[image_jump,row_jump,column_jump,color_jump]=[1,2,2,1] mostly\n",
    "        stride = [1, stride_size, stride_size, 1]\n",
    "        return tf.nn.max_pool(layer, ksize=kernel, strides=stride, padding='SAME')\n",
    "\n",
    "    def flattening_layer(self,layer):\n",
    "        #make it single dimensional\n",
    "        input_size = layer.get_shape().as_list()\n",
    "        new_size = input_size[-1] * input_size[-2] * input_size[-3]\n",
    "        return tf.reshape(layer, [-1, new_size]),new_size\n",
    "\n",
    "    def fully_connected_layer(self,layer, input_shape, output_shape):\n",
    "        #create weights and biases for the given layer shape\n",
    "        weights = self.add_weights([input_shape, output_shape])\n",
    "        biases = self.add_biases([output_shape])\n",
    "        #most important operation\n",
    "        layer = tf.matmul(layer,weights) + biases  # mX+b\n",
    "        return layer\n",
    "\n",
    "    def activation_layer(self,layer):\n",
    "        # we use Rectified linear unit Relu. it's the standard activation layer used.\n",
    "        # there are also other layer like sigmoid,tanh..etc. but relu is more efficent.\n",
    "        # function: 0 if x<0 else x.\n",
    "        return tf.nn.relu(layer)\n",
    "    pass\n",
    "\n",
    "\n",
    "#tools for image processing and data handing.\n",
    "class utils:\n",
    "    image_count = []\n",
    "    count_buffer=[]\n",
    "    class_buffer=all_classes[:]\n",
    "    def __init__(self):\n",
    "        self.image_count = []\n",
    "        self.count_buffer = []\n",
    "        for i in os.walk(data_path):\n",
    "            if len(i[2]):\n",
    "                self.image_count.append(len(i[2]))\n",
    "        self.count_buffer=self.image_count[:]\n",
    "\n",
    "    # processing images into arrays and dispatch as batches whenever called.\n",
    "    def batch_dispatch(self,batch_size=batch_size):\n",
    "        global batch_counter\n",
    "        if sum(self.count_buffer):\n",
    "\n",
    "            class_name = random.choice(self.class_buffer)\n",
    "            choice_index = all_classes.index(class_name)\n",
    "            choice_count = self.count_buffer[choice_index]\n",
    "            if choice_count==0:\n",
    "                class_name=all_classes[self.count_buffer.index(max(self.count_buffer))]\n",
    "                choice_index = all_classes.index(class_name)\n",
    "                choice_count = self.count_buffer[choice_index]\n",
    "\n",
    "            slicer=batch_size if batch_size<choice_count else choice_count\n",
    "            img_ind=self.image_count[choice_index]-choice_count\n",
    "            indices=[img_ind,img_ind+slicer]\n",
    "            images = self.generate_images(class_name,indices)\n",
    "            labels = self.generate_labels(class_name,slicer)\n",
    "\n",
    "            self.count_buffer[choice_index]=self.count_buffer[choice_index]-slicer\n",
    "        else:\n",
    "            images,labels=(None,)*2\n",
    "        return images, labels\n",
    "\n",
    "    #gives one hot for the respective labels\n",
    "    def generate_labels(self,class_name,number_of_samples):\n",
    "        one_hot_labels=[0]*number_of_classes\n",
    "        one_hot_labels[all_classes.index(class_name)]=1\n",
    "        one_hot_labels=[one_hot_labels]*number_of_samples\n",
    "        #one_hot_labels=tf.one_hot(indices=[all_classes.index(class_name)]*number_of_samples,depth=number_of_classes)\n",
    "        return one_hot_labels\n",
    "\n",
    "    # image operations\n",
    "    def generate_images(self,class_name,indices):\n",
    "        batch_images=[]\n",
    "        choice_folder=os.path.join(data_path,class_name)\n",
    "        selected_images=os.listdir(choice_folder)[indices[0]:indices[1]]\n",
    "        for image in selected_images:\n",
    "            img=cv2.imread(os.path.join(choice_folder,image))\n",
    "            batch_images.append(img)\n",
    "        return batch_images\n",
    "\n",
    "#generating our own model, explanations are given respectively\n",
    "def generate_model():\n",
    "    #MODEL ARCHITECTURE:\n",
    "    #level 1 convolution\n",
    "    network=model.conv_layer(images_ph,5,3,16,1)\n",
    "    network=model.pooling_layer(network,5,2)\n",
    "    network=model.activation_layer(network)\n",
    "    print(network)\n",
    "\n",
    "    #level 2 convolution\n",
    "    network=model.conv_layer(network,4,16,32,1)\n",
    "    network=model.pooling_layer(network,4,2)\n",
    "    network=model.activation_layer(network)\n",
    "    print(network)\n",
    "\n",
    "    #level 3 convolution\n",
    "    network=model.conv_layer(network,3,32,64,1)\n",
    "    network=model.pooling_layer(network,3,2)\n",
    "    network=model.activation_layer(network)\n",
    "    print(network)\n",
    "\n",
    "    #flattening layer\n",
    "    network,features=model.flattening_layer(network)\n",
    "    print(network)\n",
    "\n",
    "    #fully connected layer\n",
    "    network=model.fully_connected_layer(network,features,1024)\n",
    "    network=model.activation_layer(network)\n",
    "    print(network)\n",
    "\n",
    "    #output layer\n",
    "    network=model.fully_connected_layer(network,1024,number_of_classes)\n",
    "    print(network)\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "#training happens here\n",
    "def trainer(network,number_of_images):\n",
    "    #find error like squared error but better\n",
    "    cross_entropy=tf.nn.softmax_cross_entropy_with_logits_v2(logits=network,labels=labels_ph)\n",
    "\n",
    "    #now minize the above error\n",
    "    #calculate the total mean of all the errors from all the nodes\n",
    "    cost=tf.reduce_mean(cross_entropy)\n",
    "    tf.summary.scalar(\"cost\", cost)#for tensorboard visualisation\n",
    "\n",
    "    #Now backpropagate to minimise the cost in the network.\n",
    "    optimizer=tf.train.AdamOptimizer().minimize(cost)\n",
    "    #print(optimizer)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(model_save_name, graph=tf.get_default_graph())\n",
    "    merged = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver(max_to_keep=4)\n",
    "    counter=0\n",
    "    for epoch in range(epochs):\n",
    "        tools = utils()\n",
    "        for batch in range(int(number_of_images / batch_size)):\n",
    "            counter+=1\n",
    "            images, labels = tools.batch_dispatch()\n",
    "            if images == None:\n",
    "                break\n",
    "            loss,summary = session.run([cost,merged], feed_dict={images_ph: images, labels_ph: labels})\n",
    "            print('loss', loss)\n",
    "            session.run(optimizer, feed_dict={images_ph: images, labels_ph: labels})\n",
    "\n",
    "            print('Epoch number ', epoch, 'batch', batch, 'complete')\n",
    "            writer.add_summary(summary,counter)\n",
    "        saver.save(session, model_save_name)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    tools=utils()\n",
    "    model=model_tools()\n",
    "    network=ma.generate_model(images_ph,number_of_classes)\n",
    "    number_of_images = sum([len(files) for r, d, files in os.walk(\"data\")])\n",
    "    trainer(network,number_of_images)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
